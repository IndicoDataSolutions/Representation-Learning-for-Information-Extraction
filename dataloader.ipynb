{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "from utils import xml_parser, Neighbour, visualizer, candidate\n",
    "from utils import operations as op\n",
    "from utils import preprocess\n",
    "from network import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "\n",
    "def get_neighbours(list_of_neighbours, vocabulary, n_neighbours):\n",
    "    \"\"\"Returns a list of neighbours and coordinates.\"\"\"\n",
    "    neighbours = list()\n",
    "    neighbour_cords = list()\n",
    "    \n",
    "    for neighbour in list_of_neighbours:\n",
    "        if neighbour['text'] not in vocabulary:\n",
    "            vocabulary[neighbour['text']] = len(vocabulary)\n",
    "\n",
    "        neighbours.append(vocabulary[neighbour['text']])\n",
    "        neighbour_cords.append(\n",
    "            [\n",
    "                neighbour['x'],\n",
    "                neighbour['y']\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    len_neighbours = len(neighbours)\n",
    "    if len_neighbours != n_neighbours:\n",
    "        if  len_neighbours > n_neighbours:\n",
    "            neighbours = neighbours[:n_neighbours]\n",
    "            neighbour_cords = neighbour_cords[:n_neighbours]\n",
    "        else:\n",
    "            neighbours.append(vocabulary['<PAD>'])\n",
    "            neighbour_cords.extend([[0., 0.]] * (n_neighbours - len_neighbours))\n",
    "\n",
    "    return neighbours, neighbour_cords\n",
    "\n",
    "def parse_input(annotations, fields_dict, n_neighbours=5, vocabulary=None):\n",
    "    \"\"\"Generates input samples from annotations data.\"\"\"\n",
    "    \n",
    "    field_ids = list()\n",
    "    candidate_cords = list()\n",
    "    neighbours = list()\n",
    "    neighbour_cords = list()\n",
    "    labels = list()\n",
    "    if not vocabulary:\n",
    "        vocabulary = { '<PAD>':PAD }\n",
    "\n",
    "    for annotation in tqdm(annotations, desc='Parsing Input'):\n",
    "        \n",
    "        fields = annotation['fields']\n",
    "        \n",
    "        for field in fields:\n",
    "            if fields[field]['true_candidates']:\n",
    "                _neighbours, _neighbour_cords = get_neighbours(\n",
    "                    fields[field]['true_candidates'][0]['neighbours'],\n",
    "                    vocabulary, n_neighbours\n",
    "                )\n",
    "                labels.append(1.)\n",
    "                field_ids.append(fields_dict[field])\n",
    "                candidate_cords.append(\n",
    "                    [\n",
    "                        fields[field]['true_candidates'][0]['x'],\n",
    "                        fields[field]['true_candidates'][0]['y']\n",
    "                    ]\n",
    "                )\n",
    "                neighbours.append(_neighbours)\n",
    "                neighbour_cords.append(_neighbour_cords)\n",
    "               \n",
    "                for candidate in fields[field]['other_candidates']:\n",
    "\n",
    "                    _neighbours, _neighbour_cords = get_neighbours(candidate['neighbours'], vocabulary, n_neighbours)\n",
    "                    labels.append(0.)\n",
    "                    field_ids.append(fields_dict[field])\n",
    "                    candidate_cords.append(\n",
    "                        [\n",
    "                            candidate['x'],\n",
    "                            candidate['y']\n",
    "                        ]\n",
    "                    )\n",
    "                    neighbours.append(_neighbours)\n",
    "                    neighbour_cords.append(_neighbour_cords)\n",
    "                    \n",
    "                    \n",
    "    return field_ids, candidate_cords, neighbours, neighbour_cords, labels, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {'<PAD>':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_dict = {'invoice_date':0, 'invoice_no':1, 'total':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentsDataset(data.Dataset):\n",
    "    \"\"\"Stores the annotated documents dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, xmls_path, ocr_path, image_path,candidate_path,\n",
    "                 field_dict, n_neighbour=5, vocab=None):\n",
    "        \"\"\" Initialize the dataset with preprocessing \"\"\"\n",
    "        annotation, classes_count, class_mapping = xml_parser.get_data(xmls_path)\n",
    "        annotation = candidate.attach_candidate(annotation, candidate_path)\n",
    "        annotation = Neighbour.attach_neighbour(annotation, ocr_path)\n",
    "        annotation = op.normalize_positions(annotation)\n",
    "        _data = parse_input(annotation, field_dict, n_neighbour, vocab)\n",
    "        self.field_ids, self.candidate_cords, self.neighbours, self.neighbour_cords, self.labels, self.vocab = _data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.field_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return (\n",
    "            torch.tensor(self.field_ids[idx]),\n",
    "            torch.tensor(self.candidate_cords[idx]),\n",
    "            torch.tensor(self.neighbours[idx]),\n",
    "            torch.tensor(self.neighbour_cords[idx]),\n",
    "            self.labels[idx]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_dir = Path.cwd()\n",
    "xmls_path = this_dir / \"dataset\" / \"xmls\"\n",
    "ocr_path = this_dir / \"dataset\" / \"tesseract_results_lstm\"\n",
    "image_path = this_dir / \"dataset\" / \"images\"\n",
    "candidate_path = this_dir / \"dataset\" / \"candidates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Annotations: 505it [00:00, 576.57it/s]\n",
      "Attaching Candidate: 100%|██████████| 505/505 [00:01<00:00, 461.50it/s]\n",
      "Attaching Neighbours: 100%|██████████| 505/505 [01:17<00:00,  4.75it/s]\n",
      "normalizing position coordinates: 100%|██████████| 505/505 [00:01<00:00, 272.11it/s]\n"
     ]
    }
   ],
   "source": [
    "annotation, classes_count, class_mapping = xml_parser.get_data(xmls_path)\n",
    "annotation = candidate.attach_candidate(annotation, candidate_path)\n",
    "annotation = Neighbour.attach_neighbour(annotation, ocr_path)\n",
    "annotation = op.normalize_positions(annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing Input: 100%|██████████| 1/1 [00:00<00:00, 167.00it/s]\n"
     ]
    }
   ],
   "source": [
    "field, c_co, ns, n_cos, ls, v=parse_input(annotation[:1], field_dict, 5, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.09094117647058825, -0.0569090909090909],\n",
       " [-0.030823529411764722, -0.0579090909090909],\n",
       " [0.011176470588235288, -0.0149090909090909],\n",
       " [0.02564705882352941, 9.090909090909982e-05],\n",
       " [0.061176470588235304, 0.0]]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cos[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Annotations: 505it [00:00, 702.48it/s]\n",
      "Attaching Candidate: 100%|██████████| 505/505 [00:01<00:00, 459.64it/s]\n",
      "Attaching Neighbours: 100%|██████████| 505/505 [01:17<00:00,  4.73it/s]\n",
      "normalizing position coordinates: 100%|██████████| 505/505 [00:02<00:00, 252.01it/s]\n",
      "Parsing Input: 100%|██████████| 505/505 [00:00<00:00, 522.03it/s]\n"
     ]
    }
   ],
   "source": [
    "datas = dataset.DocumentsDataset(xmls_path, ocr_path, image_path, candidate_path, field_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1),\n",
       " tensor([0.6985, 0.0865]),\n",
       " tensor([1, 2, 3, 4, 5]),\n",
       " tensor([[ 0.0176, -0.0512],\n",
       "         [ 0.0472, -0.0512],\n",
       "         [ 0.0936, -0.0511],\n",
       "         [ 0.1104, -0.0143],\n",
       "         [-0.0133, -0.0145]]),\n",
       " 1.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "datal = data.DataLoader(datas, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_ids, c_cords, neighs, neigh_cords, labels = next(iter(datal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "f =(2,3,4)\n",
    "a, b, c = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X y \n",
    "y = [B, 1]\n",
    "X = [B, (3 + N * 3)]\n",
    "\n",
    "\n",
    "y words cords\n",
    "\n",
    "words [B, N]\n",
    "cords [B, N, 2]\n",
    "\n",
    "words [B, N] = [B, N, D]\n",
    "cords [B, N, 2 ] = [B, N, D]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
