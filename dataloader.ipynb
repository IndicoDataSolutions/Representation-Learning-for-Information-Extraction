{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "from utils import xml_parser, Neighbour, visualizer, candidate\n",
    "from utils import operations as op\n",
    "from utils import preprocess\n",
    "from network import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "\n",
    "def get_neighbours(list_of_neighbours, vocabulary, n_neighbours):\n",
    "    \"\"\"Returns a list of neighbours and coordinates.\"\"\"\n",
    "    neighbours = list()\n",
    "    \n",
    "    for neighbour in list_of_neighbours:\n",
    "        if neighbour['text'] not in vocabulary:\n",
    "            vocabulary[neighbour['text']] = len(vocabulary)\n",
    "\n",
    "        neighbours.extend(\n",
    "            [\n",
    "                vocabulary[neighbour['text']],\n",
    "                neighbour['x'],\n",
    "                neighbour['y']\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    len_neighbours = int(len(neighbours) / 3) \n",
    "    if len_neighbours != n_neighbours:\n",
    "        if  len_neighbours > n_neighbours:\n",
    "            neighbours = neighbours[:(n_neighbours * 3)]\n",
    "        else:\n",
    "            neighbours.extend(['<PAD>', 0., 0.] * (n_neighbours - len_neighbours))\n",
    "\n",
    "    return neighbours\n",
    "\n",
    "def parse_input(annotations, fields_dict, n_neighbours=5, vocabulary=None):\n",
    "    \"\"\"Generates input samples from annotations data.\"\"\"\n",
    "\n",
    "    x = list()\n",
    "    Y = list()\n",
    "    if not vocabulary:\n",
    "        vocabulary = { '<PAD>':PAD }\n",
    "\n",
    "    for annotation in tqdm(annotations, desc='Parsing Input'):\n",
    "        \n",
    "        fields = annotation['fields']\n",
    "        \n",
    "        for field in fields:\n",
    "            if fields[field]['true_candidates']:\n",
    "                Y.append(1.)\n",
    "                neighbours = get_neighbours(\n",
    "                    fields[field]['true_candidates'][0]['neighbours'],\n",
    "                    vocabulary, n_neighbours\n",
    "                )\n",
    "                x.append(\n",
    "                    [\n",
    "                        fields_dict[field],\n",
    "                        fields[field]['true_candidates'][0]['x'],\n",
    "                        fields[field]['true_candidates'][0]['y']\n",
    "                    ] + neighbours)\n",
    "\n",
    "                for candidate in fields[field]['other_candidates']:\n",
    "\n",
    "                    Y.append(0.)\n",
    "                    neighbours = get_neighbours(candidate['neighbours'], vocabulary, n_neighbours)\n",
    "                    x.append(\n",
    "                        [\n",
    "                            fields_dict[field],\n",
    "                            candidate['x'],\n",
    "                            candidate['y'],\n",
    "                        ] + neighbours)\n",
    "\n",
    "    return x, Y, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {'<PAD>':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'annotation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0be46275f5ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_neighbours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fields'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'invoice_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'true_candidates'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'neighbours'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'annotation' is not defined"
     ]
    }
   ],
   "source": [
    "_ = get_neighbours(annotation[1]['fields']['invoice_date']['true_candidates'][0]['neighbours'], vocab, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_dict = {'invoice_date':0, 'invoice_no':1, 'total':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing Input: 100%|██████████| 505/505 [00:00<00:00, 705.20it/s]\n"
     ]
    }
   ],
   "source": [
    "x, Y, vocab = parse_input(annotation, field_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentsDataset(data.Dataset):\n",
    "    \"\"\"Stores the annotated documents dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, xmls_path, ocr_path, image_path,candidate_path,\n",
    "                 field_dict, n_neighbour=5, vocab=None):\n",
    "        \"\"\" Initialize the dataset with preprocessing \"\"\"\n",
    "        annotation, classes_count, class_mapping = xml_parser.get_data(xmls_path)\n",
    "        annotation = candidate.attach_candidate(annotation, candidate_path)\n",
    "        annotation = Neighbour.attach_neighbour(annotation, ocr_path)\n",
    "        annotation = op.normalize_positions(annotation)\n",
    "        self.features, self.labels, self.vocab = preprocess.parse_input(annotation, field_dict, n_neighbour, vocab)        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return torch.tensor(self.features[idx]), self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_dir = Path.cwd()\n",
    "xmls_path = this_dir / \"dataset\" / \"xmls\"\n",
    "ocr_path = this_dir / \"dataset\" / \"tesseract_results_lstm\"\n",
    "image_path = this_dir / \"dataset\" / \"images\"\n",
    "candidate_path = this_dir / \"dataset\" / \"candidates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Annotations: 505it [00:00, 803.05it/s]\n",
      "Attaching Candidate: 100%|██████████| 505/505 [00:01<00:00, 439.85it/s]\n",
      "Attaching Neighbours: 100%|██████████| 505/505 [01:17<00:00,  4.56it/s]\n",
      "normalizing position coordinates: 100%|██████████| 505/505 [00:01<00:00, 275.64it/s]\n",
      "Parsing Input: 100%|██████████| 505/505 [00:00<00:00, 819.88it/s]\n"
     ]
    }
   ],
   "source": [
    "datas = dataset.DocumentsDataset(xmls_path, ocr_path, image_path, candidate_path, field_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.0000,  0.6985,  0.0865,  1.0000,  0.0176, -0.0512,  2.0000,  0.0472,\n",
       "         -0.0512,  3.0000,  0.0936, -0.0511,  4.0000,  0.1104, -0.0143,  5.0000,\n",
       "         -0.0133, -0.0145]), 1.0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "datal = data.DataLoader(datas, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, Y = next(iter(datal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000e+00,  2.2400e-01,  9.3091e-02,  2.2000e+01, -9.0941e-02,\n",
       "        -5.6909e-02,  2.3000e+01, -3.0824e-02, -5.7909e-02,  2.4000e+01,\n",
       "         1.1176e-02, -1.4909e-02,  2.5000e+01,  2.5647e-02,  9.0909e-05,\n",
       "         2.6000e+01,  6.1176e-02,  0.0000e+00])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
